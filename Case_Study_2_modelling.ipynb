{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Case Study 2 modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "f290tepOPogm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVcXLP8QParY"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing bpemb"
      ],
      "metadata": {
        "id": "t0Y_gdAJPudA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRyI4iKVPcZr",
        "outputId": "0252c99c-cb11-46e2-c131-ea98e572c1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.21.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2021.10.8)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.3 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the Preprocessed csv file"
      ],
      "metadata": {
        "id": "smrp20p8Pz-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_output =pd.read_csv('/content/drive/MyDrive/converted_for_training_1M.csv')"
      ],
      "metadata": {
        "id": "DhtASA6YPjSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_output.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "bPMUu7-2Pvdy",
        "outputId": "69184974-3d8b-46b6-eaf6-8857d03bf9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              input  \\\n",
              "0           0                   <start> website definitely <end>   \n",
              "1           1              <start> website definitely read <end>   \n",
              "2           2           <start> website definitely read at <end>   \n",
              "3           3     <start> website definitely read at least <end>   \n",
              "4           4  <start> website definitely read at least the <...   \n",
              "\n",
              "                                              output  \\\n",
              "0  <start> read at least the 2nd to last paragrap...   \n",
              "1  <start> at least the 2nd to last paragraph in ...   \n",
              "2  <start> least the 2nd to last paragraph in the...   \n",
              "3  <start> the 2nd to last paragraph in the pdf <...   \n",
              "4     <start> 2nd to last paragraph in the pdf <end>   \n",
              "\n",
              "                                      decoder_output  \n",
              "0  read at least the 2nd to last paragraph in the...  \n",
              "1  at least the 2nd to last paragraph in the pdf ...  \n",
              "2   least the 2nd to last paragraph in the pdf <end>  \n",
              "3         the 2nd to last paragraph in the pdf <end>  \n",
              "4             2nd to last paragraph in the pdf <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce0568ba-0266-4c83-ab9f-9521af5d529c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>decoder_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;start&gt; website definitely &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; read at least the 2nd to last paragrap...</td>\n",
              "      <td>read at least the 2nd to last paragraph in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; website definitely read &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; at least the 2nd to last paragraph in ...</td>\n",
              "      <td>at least the 2nd to last paragraph in the pdf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>&lt;start&gt; website definitely read at &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; least the 2nd to last paragraph in the...</td>\n",
              "      <td>least the 2nd to last paragraph in the pdf &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>&lt;start&gt; website definitely read at least &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; the 2nd to last paragraph in the pdf &lt;...</td>\n",
              "      <td>the 2nd to last paragraph in the pdf &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>&lt;start&gt; website definitely read at least the &lt;...</td>\n",
              "      <td>&lt;start&gt; 2nd to last paragraph in the pdf &lt;end&gt;</td>\n",
              "      <td>2nd to last paragraph in the pdf &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce0568ba-0266-4c83-ab9f-9521af5d529c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce0568ba-0266-4c83-ab9f-9521af5d529c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce0568ba-0266-4c83-ab9f-9521af5d529c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing the start and end tags"
      ],
      "metadata": {
        "id": "76KJdciDP5Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_start_end_input(str):\n",
        "  return ' '.join(str.split(' ')[1:-1])\n",
        "\n",
        "def remove_start_output(str):\n",
        "  return ' '.join(str.split(' ')[:-1])"
      ],
      "metadata": {
        "id": "pkcKYxo9mltP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_output['input'] = input_output['input'].transform(remove_start_end_input)\n",
        "input_output['output'] = input_output['output'].transform(remove_start_end_input)\n",
        "input_output['decoder_output'] = input_output['decoder_output'].transform(remove_start_output)"
      ],
      "metadata": {
        "id": "MKBY3qFHnYYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_output.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "KUPIpW0gnpjr",
        "outputId": "362705a5-d0f8-4adb-88b1-54f58acaa30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                 input  \\\n",
              "0           0                    website definitely   \n",
              "1           1               website definitely read   \n",
              "2           2            website definitely read at   \n",
              "3           3      website definitely read at least   \n",
              "4           4  website definitely read at least the   \n",
              "\n",
              "                                              output  \\\n",
              "0  read at least the 2nd to last paragraph in the...   \n",
              "1      at least the 2nd to last paragraph in the pdf   \n",
              "2         least the 2nd to last paragraph in the pdf   \n",
              "3               the 2nd to last paragraph in the pdf   \n",
              "4                   2nd to last paragraph in the pdf   \n",
              "\n",
              "                                      decoder_output  \n",
              "0  read at least the 2nd to last paragraph in the...  \n",
              "1      at least the 2nd to last paragraph in the pdf  \n",
              "2         least the 2nd to last paragraph in the pdf  \n",
              "3               the 2nd to last paragraph in the pdf  \n",
              "4                   2nd to last paragraph in the pdf  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6c3f294-29a8-4f79-9fe0-e09af8be5869\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>decoder_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>website definitely</td>\n",
              "      <td>read at least the 2nd to last paragraph in the...</td>\n",
              "      <td>read at least the 2nd to last paragraph in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>website definitely read</td>\n",
              "      <td>at least the 2nd to last paragraph in the pdf</td>\n",
              "      <td>at least the 2nd to last paragraph in the pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>website definitely read at</td>\n",
              "      <td>least the 2nd to last paragraph in the pdf</td>\n",
              "      <td>least the 2nd to last paragraph in the pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>website definitely read at least</td>\n",
              "      <td>the 2nd to last paragraph in the pdf</td>\n",
              "      <td>the 2nd to last paragraph in the pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>website definitely read at least the</td>\n",
              "      <td>2nd to last paragraph in the pdf</td>\n",
              "      <td>2nd to last paragraph in the pdf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6c3f294-29a8-4f79-9fe0-e09af8be5869')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6c3f294-29a8-4f79-9fe0-e09af8be5869 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6c3f294-29a8-4f79-9fe0-e09af8be5869');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpemb import BPEmb"
      ],
      "metadata": {
        "id": "wtxBGajfP7-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpemb_en = BPEmb(lang=\"en\",vs=50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Ldaew7P04y",
        "outputId": "e931de2a-775a-41f4-98a7-e3246f4ff871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs50000.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1100587/1100587 [00:01<00:00, 711358.47B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs50000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18972246/18972246 [00:03<00:00, 5652398.27B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bpemb_en.vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjCSknmfQDPl",
        "outputId": "894358f0-82b2-49ac-ca75-378d4eb96c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Encoder input and Decoder input and output"
      ],
      "metadata": {
        "id": "tSWJ9oBbP_Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = np.array(input_output['input'])\n",
        "decoder_input = np.array(input_output['output'])\n",
        "decoder_target = np.array(input_output['decoder_output'])"
      ],
      "metadata": {
        "id": "5wZDoqfMQ_c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train, encoder_input_test, decoder_input_train, decoder_input_test, decoder_target_train, decoder_target_test = train_test_split(encoder_input, decoder_input,decoder_target, test_size=0.3)"
      ],
      "metadata": {
        "id": "Q3or32b5RD1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = bpemb_en.encode_ids_with_bos_eos(encoder_input_train)\n",
        "encoder_input_test = bpemb_en.encode_ids_with_bos_eos(encoder_input_test)\n",
        "decoder_input_train = bpemb_en.encode_ids_with_bos_eos(decoder_input_train)\n",
        "decoder_input_test = bpemb_en.encode_ids_with_bos_eos(decoder_input_test)\n",
        "decoder_target_train = bpemb_en.encode_ids_with_eos(decoder_target_train)\n",
        "decoder_target_test = bpemb_en.encode_ids_with_eos(decoder_target_test)"
      ],
      "metadata": {
        "id": "0ilqhqW6RIFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input_train.shape, encoder_input_test.shape)\n",
        "print(decoder_input_train.shape, decoder_input_test.shape)\n",
        "print(decoder_target_train.shape, decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VWehHhJRF2m",
        "outputId": "31bef615-996f-42c3-ebc8-c5064e4bf155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700000,) (300000,)\n",
            "(700000,) (300000,)\n",
            "(700000,) (300000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input_train[0])\n",
        "print(encoder_input_test[0])\n",
        "print(decoder_input_train[0])\n",
        "print(decoder_input_test[0])\n",
        "print(decoder_target_train[0])\n",
        "print(decoder_target_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbOlzCiQk-rK",
        "outputId": "fb5c624d-96ee-43e7-f178-cd68b549375f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 4538, 2]\n",
            "[1, 774, 26, 6663, 6663, 1964, 35933, 2]\n",
            "[1, 32, 774, 15725, 71, 146, 963, 2]\n",
            "[1, 663, 515, 2780, 39617, 49934, 20915, 1645, 32478, 3393, 3589, 774, 24, 2]\n",
            "[32, 774, 15725, 71, 146, 963, 2]\n",
            "[663, 515, 2780, 39617, 49934, 20915, 1645, 32478, 3393, 3589, 774, 24, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "max_length_in = max_length(encoder_input_train)\n",
        "max_length_out = max_length(decoder_input_train)\n",
        "\n",
        "encoder_input_train = keras.preprocessing.sequence.pad_sequences(encoder_input_train, maxlen=max_length_in, padding=\"post\")\n",
        "decoder_input_train = keras.preprocessing.sequence.pad_sequences(decoder_input_train, maxlen=max_length_out, padding=\"post\")\n",
        "decoder_target_train = keras.preprocessing.sequence.pad_sequences(decoder_target_train, maxlen=max_length_out, padding=\"post\")\n",
        "\n",
        "encoder_input_test = keras.preprocessing.sequence.pad_sequences(encoder_input_test, maxlen=max_length_in, padding=\"post\")\n",
        "decoder_input_test = keras.preprocessing.sequence.pad_sequences(decoder_input_test, maxlen=max_length_out, padding=\"post\")\n",
        "decoder_target_test = keras.preprocessing.sequence.pad_sequences(decoder_target_test, maxlen=max_length_out, padding=\"post\")"
      ],
      "metadata": {
        "id": "sUEON3qmRbIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length_in, max_length_out)\n",
        "gru_dim = 256\n",
        "batch_size = 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCenr_vlRggq",
        "outputId": "56314fd4-44e3-4fd4-cf7d-4a4e7e0913c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149 146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Encoder - Decoder Model"
      ],
      "metadata": {
        "id": "oG28zejJQQT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, GRU, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import TerminateOnNaN\n",
        "import datetime"
      ],
      "metadata": {
        "id": "7iXo1Et7xlfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "\n",
        "input_encoder = Input(shape = (max_length_in,))\n",
        "embedding_encoder = Embedding(bpemb_en.vectors.shape[0],100,embeddings_initializer = keras.initializers.Constant(bpemb_en.vectors), input_length=max_length_in,trainable=False)\n",
        "gru_en = GRU(units = gru_dim, return_sequences = True, return_state = True)\n",
        "gru_bi_encoder = Bidirectional(gru_en)\n",
        "\n",
        "#Decoder\n",
        "input_decoder = Input(shape=(None,))\n",
        "embedding_decoder = Embedding(bpemb_en.vectors.shape[0],100,embeddings_initializer = keras.initializers.Constant(bpemb_en.vectors), input_length=max_length_out,trainable=False)\n",
        "gru_de = GRU(units = gru_dim*2, return_sequences = True, return_state = True)\n",
        "\n",
        "\n",
        "#create model flow\n",
        "#encoder flow\n",
        "input_en = input_encoder\n",
        "embedding_en = embedding_encoder(input_en)\n",
        "encoder_out, forward_state, backward_state = gru_bi_encoder(embedding_en)\n",
        "state_h = keras.layers.Concatenate()([forward_state, backward_state])\n",
        "\n",
        "#decoder flow\n",
        "input_de = input_decoder\n",
        "embedding_de = embedding_decoder(input_de)\n",
        "decoder_out, _ = gru_de(embedding_de, initial_state=state_h)\n",
        "dropout1 = Dropout(0.2)(decoder_out)\n",
        "decoder_dense_1 = keras.layers.Dense(128, activation=\"relu\")(dropout1)\n",
        "dropout2 = Dropout(0.2)(decoder_dense_1)\n",
        "decoder_dense_output = keras.layers.Dense(bpemb_en.vectors.shape[0], activation=\"softmax\")(dropout2)\n",
        "\n"
      ],
      "metadata": {
        "id": "2KzkdFzkr1ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ModelCheckpoint = Saves the model when the acc. metric improve\n",
        "filepath=\"/content/drive/MyDrive/Best_Model_L1_revised/weights-{epoch:02d}-{val_perplexity:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_perplexity',  verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "#Stops when the acc. metric does not imporve for 2 iterations\n",
        "earlystop = EarlyStopping(monitor='val_perplexity', patience=5, verbose=15,mode='min')\n",
        "\n",
        "#Creates tensorboard logs \n",
        "log_dir=\"/content/drive/MyDrive/logs_revised/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "#terminates when the loss becomes NaN\n",
        "TerminateWhenLossNaN = TerminateOnNaN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giKLYFSdwhCq",
        "outputId": "d2a2bdaf-ee6c-4d6a-b7c9-d15cba379b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    return keras.backend.exp(keras.backend.mean(keras.backend.sparse_categorical_crossentropy(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "ZgWsM8qzdycv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model that uses the Encoder and the Decoder\n",
        "model = keras.models.Model([input_encoder, input_decoder], decoder_dense_output)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[perplexity])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlKZrNIHwY83",
        "outputId": "df908d5f-1151-4e4e-eb45-29933f749811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 149)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 149, 100)     5000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 149, 512),   549888      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    5000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['bidirectional[0][1]',          \n",
            "                                                                  'bidirectional[0][2]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, None, 512),  943104      ['embedding_1[0][0]',            \n",
            "                                 (None, 512)]                     'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 512)    0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    65664       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 128)    0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 50000)  6450000     ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,008,656\n",
            "Trainable params: 8,008,656\n",
            "Non-trainable params: 10,000,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit([encoder_input_train, decoder_input_train], decoder_target_train,\n",
        "                 batch_size=batch_size,\n",
        "                 epochs=epochs,\n",
        "                 validation_split=0.2\n",
        "                 ,callbacks = [checkpoint,TerminateWhenLossNaN,tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y27Pw6DhVym8",
        "outputId": "09e6fb52-6005-4237-9bdc-c1562a1653c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.3241 - perplexity: 48.6701\n",
            "Epoch 1: val_perplexity improved from inf to 1.28693, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-01-1.2869.hdf5\n",
            "4375/4375 [==============================] - 1959s 446ms/step - loss: 0.3241 - perplexity: 48.6701 - val_loss: 0.2521 - val_perplexity: 1.2869\n",
            "Epoch 2/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.2439 - perplexity: 1.2765\n",
            "Epoch 2: val_perplexity improved from 1.28693 to 1.24087, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-02-1.2409.hdf5\n",
            "4375/4375 [==============================] - 2066s 472ms/step - loss: 0.2439 - perplexity: 1.2765 - val_loss: 0.2157 - val_perplexity: 1.2409\n",
            "Epoch 3/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.2199 - perplexity: 1.2462\n",
            "Epoch 3: val_perplexity improved from 1.24087 to 1.21848, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-03-1.2185.hdf5\n",
            "4375/4375 [==============================] - 2092s 478ms/step - loss: 0.2199 - perplexity: 1.2462 - val_loss: 0.1975 - val_perplexity: 1.2185\n",
            "Epoch 4/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.2079 - perplexity: 1.2313\n",
            "Epoch 4: val_perplexity improved from 1.21848 to 1.20749, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-04-1.2075.hdf5\n",
            "4375/4375 [==============================] - 2018s 461ms/step - loss: 0.2079 - perplexity: 1.2313 - val_loss: 0.1885 - val_perplexity: 1.2075\n",
            "Epoch 5/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.2011 - perplexity: 1.2228\n",
            "Epoch 5: val_perplexity improved from 1.20749 to 1.20011, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-05-1.2001.hdf5\n",
            "4375/4375 [==============================] - 2007s 459ms/step - loss: 0.2011 - perplexity: 1.2228 - val_loss: 0.1823 - val_perplexity: 1.2001\n",
            "Epoch 6/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1965 - perplexity: 1.2173\n",
            "Epoch 6: val_perplexity improved from 1.20011 to 1.19606, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-06-1.1961.hdf5\n",
            "4375/4375 [==============================] - 1997s 456ms/step - loss: 0.1965 - perplexity: 1.2173 - val_loss: 0.1790 - val_perplexity: 1.1961\n",
            "Epoch 7/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1934 - perplexity: 1.2134\n",
            "Epoch 7: val_perplexity improved from 1.19606 to 1.19229, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-07-1.1923.hdf5\n",
            "4375/4375 [==============================] - 1986s 454ms/step - loss: 0.1934 - perplexity: 1.2134 - val_loss: 0.1758 - val_perplexity: 1.1923\n",
            "Epoch 8/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1910 - perplexity: 1.2106\n",
            "Epoch 8: val_perplexity improved from 1.19229 to 1.19006, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-08-1.1901.hdf5\n",
            "4375/4375 [==============================] - 1994s 456ms/step - loss: 0.1910 - perplexity: 1.2106 - val_loss: 0.1739 - val_perplexity: 1.1901\n",
            "Epoch 9/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1892 - perplexity: 1.2084\n",
            "Epoch 9: val_perplexity improved from 1.19006 to 1.18797, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-09-1.1880.hdf5\n",
            "4375/4375 [==============================] - 1991s 455ms/step - loss: 0.1892 - perplexity: 1.2084 - val_loss: 0.1722 - val_perplexity: 1.1880\n",
            "Epoch 10/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1877 - perplexity: 1.2066\n",
            "Epoch 10: val_perplexity improved from 1.18797 to 1.18659, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-10-1.1866.hdf5\n",
            "4375/4375 [==============================] - 1993s 456ms/step - loss: 0.1877 - perplexity: 1.2066 - val_loss: 0.1710 - val_perplexity: 1.1866\n",
            "Epoch 11/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1864 - perplexity: 1.2051\n",
            "Epoch 11: val_perplexity improved from 1.18659 to 1.18515, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-11-1.1852.hdf5\n",
            "4375/4375 [==============================] - 1985s 454ms/step - loss: 0.1864 - perplexity: 1.2051 - val_loss: 0.1698 - val_perplexity: 1.1852\n",
            "Epoch 12/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1854 - perplexity: 1.2038\n",
            "Epoch 12: val_perplexity improved from 1.18515 to 1.18438, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-12-1.1844.hdf5\n",
            "4375/4375 [==============================] - 1991s 455ms/step - loss: 0.1854 - perplexity: 1.2038 - val_loss: 0.1691 - val_perplexity: 1.1844\n",
            "Epoch 13/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1845 - perplexity: 1.2027\n",
            "Epoch 13: val_perplexity improved from 1.18438 to 1.18343, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-13-1.1834.hdf5\n",
            "4375/4375 [==============================] - 1990s 455ms/step - loss: 0.1845 - perplexity: 1.2027 - val_loss: 0.1683 - val_perplexity: 1.1834\n",
            "Epoch 14/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1837 - perplexity: 1.2018\n",
            "Epoch 14: val_perplexity improved from 1.18343 to 1.18261, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-14-1.1826.hdf5\n",
            "4375/4375 [==============================] - 1991s 455ms/step - loss: 0.1837 - perplexity: 1.2018 - val_loss: 0.1676 - val_perplexity: 1.1826\n",
            "Epoch 15/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1830 - perplexity: 1.2010\n",
            "Epoch 15: val_perplexity improved from 1.18261 to 1.18165, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-15-1.1817.hdf5\n",
            "4375/4375 [==============================] - 1989s 455ms/step - loss: 0.1830 - perplexity: 1.2010 - val_loss: 0.1668 - val_perplexity: 1.1817\n",
            "Epoch 16/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1824 - perplexity: 1.2001\n",
            "Epoch 16: val_perplexity improved from 1.18165 to 1.18129, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-16-1.1813.hdf5\n",
            "4375/4375 [==============================] - 1998s 457ms/step - loss: 0.1824 - perplexity: 1.2001 - val_loss: 0.1665 - val_perplexity: 1.1813\n",
            "Epoch 17/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1818 - perplexity: 1.1995\n",
            "Epoch 17: val_perplexity improved from 1.18129 to 1.18053, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-17-1.1805.hdf5\n",
            "4375/4375 [==============================] - 1999s 457ms/step - loss: 0.1818 - perplexity: 1.1995 - val_loss: 0.1659 - val_perplexity: 1.1805\n",
            "Epoch 18/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1813 - perplexity: 1.1989\n",
            "Epoch 18: val_perplexity improved from 1.18053 to 1.18010, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-18-1.1801.hdf5\n",
            "4375/4375 [==============================] - 1994s 456ms/step - loss: 0.1813 - perplexity: 1.1989 - val_loss: 0.1655 - val_perplexity: 1.1801\n",
            "Epoch 19/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1809 - perplexity: 1.1984\n",
            "Epoch 19: val_perplexity improved from 1.18010 to 1.17949, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-19-1.1795.hdf5\n",
            "4375/4375 [==============================] - 1994s 456ms/step - loss: 0.1809 - perplexity: 1.1984 - val_loss: 0.1650 - val_perplexity: 1.1795\n",
            "Epoch 20/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1804 - perplexity: 1.1978\n",
            "Epoch 20: val_perplexity did not improve from 1.17949\n",
            "4375/4375 [==============================] - 1983s 453ms/step - loss: 0.1804 - perplexity: 1.1978 - val_loss: 0.1653 - val_perplexity: 1.1798\n",
            "Epoch 21/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1800 - perplexity: 1.1974\n",
            "Epoch 21: val_perplexity improved from 1.17949 to 1.17902, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-21-1.1790.hdf5\n",
            "4375/4375 [==============================] - 1995s 456ms/step - loss: 0.1800 - perplexity: 1.1974 - val_loss: 0.1646 - val_perplexity: 1.1790\n",
            "Epoch 22/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1797 - perplexity: 1.1970\n",
            "Epoch 22: val_perplexity improved from 1.17902 to 1.17849, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-22-1.1785.hdf5\n",
            "4375/4375 [==============================] - 1992s 455ms/step - loss: 0.1797 - perplexity: 1.1970 - val_loss: 0.1642 - val_perplexity: 1.1785\n",
            "Epoch 23/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1793 - perplexity: 1.1965\n",
            "Epoch 23: val_perplexity improved from 1.17849 to 1.17761, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-23-1.1776.hdf5\n",
            "4375/4375 [==============================] - 1992s 455ms/step - loss: 0.1793 - perplexity: 1.1965 - val_loss: 0.1634 - val_perplexity: 1.1776\n",
            "Epoch 24/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1790 - perplexity: 1.1961\n",
            "Epoch 24: val_perplexity did not improve from 1.17761\n",
            "4375/4375 [==============================] - 1980s 453ms/step - loss: 0.1790 - perplexity: 1.1961 - val_loss: 0.1637 - val_perplexity: 1.1780\n",
            "Epoch 25/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1787 - perplexity: 1.1958\n",
            "Epoch 25: val_perplexity did not improve from 1.17761\n",
            "4375/4375 [==============================] - 1983s 453ms/step - loss: 0.1787 - perplexity: 1.1958 - val_loss: 0.1637 - val_perplexity: 1.1779\n",
            "Epoch 26/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1784 - perplexity: 1.1954\n",
            "Epoch 26: val_perplexity improved from 1.17761 to 1.17716, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-26-1.1772.hdf5\n",
            "4375/4375 [==============================] - 1991s 455ms/step - loss: 0.1784 - perplexity: 1.1954 - val_loss: 0.1630 - val_perplexity: 1.1772\n",
            "Epoch 27/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1781 - perplexity: 1.1950\n",
            "Epoch 27: val_perplexity improved from 1.17716 to 1.17689, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-27-1.1769.hdf5\n",
            "4375/4375 [==============================] - 1996s 456ms/step - loss: 0.1781 - perplexity: 1.1950 - val_loss: 0.1628 - val_perplexity: 1.1769\n",
            "Epoch 28/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1779 - perplexity: 1.1948\n",
            "Epoch 28: val_perplexity improved from 1.17689 to 1.17643, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-28-1.1764.hdf5\n",
            "4375/4375 [==============================] - 1998s 457ms/step - loss: 0.1779 - perplexity: 1.1948 - val_loss: 0.1624 - val_perplexity: 1.1764\n",
            "Epoch 29/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1777 - perplexity: 1.1945\n",
            "Epoch 29: val_perplexity improved from 1.17643 to 1.17630, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-29-1.1763.hdf5\n",
            "4375/4375 [==============================] - 2005s 458ms/step - loss: 0.1777 - perplexity: 1.1945 - val_loss: 0.1623 - val_perplexity: 1.1763\n",
            "Epoch 30/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1774 - perplexity: 1.1942\n",
            "Epoch 30: val_perplexity improved from 1.17630 to 1.17620, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-30-1.1762.hdf5\n",
            "4375/4375 [==============================] - 1994s 456ms/step - loss: 0.1774 - perplexity: 1.1942 - val_loss: 0.1622 - val_perplexity: 1.1762\n",
            "Epoch 31/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1771 - perplexity: 1.1939\n",
            "Epoch 31: val_perplexity improved from 1.17620 to 1.17553, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-31-1.1755.hdf5\n",
            "4375/4375 [==============================] - 2005s 458ms/step - loss: 0.1771 - perplexity: 1.1939 - val_loss: 0.1616 - val_perplexity: 1.1755\n",
            "Epoch 32/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1769 - perplexity: 1.1936\n",
            "Epoch 32: val_perplexity improved from 1.17553 to 1.17549, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-32-1.1755.hdf5\n",
            "4375/4375 [==============================] - 2000s 457ms/step - loss: 0.1769 - perplexity: 1.1936 - val_loss: 0.1616 - val_perplexity: 1.1755\n",
            "Epoch 33/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1769 - perplexity: 1.1936\n",
            "Epoch 33: val_perplexity did not improve from 1.17549\n",
            "4375/4375 [==============================] - 1985s 454ms/step - loss: 0.1769 - perplexity: 1.1936 - val_loss: 0.1626 - val_perplexity: 1.1767\n",
            "Epoch 34/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1766 - perplexity: 1.1932\n",
            "Epoch 34: val_perplexity improved from 1.17549 to 1.17499, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-34-1.1750.hdf5\n",
            "4375/4375 [==============================] - 2004s 458ms/step - loss: 0.1766 - perplexity: 1.1932 - val_loss: 0.1612 - val_perplexity: 1.1750\n",
            "Epoch 35/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1768 - perplexity: 1.1935\n",
            "Epoch 35: val_perplexity did not improve from 1.17499\n",
            "4375/4375 [==============================] - 1989s 455ms/step - loss: 0.1768 - perplexity: 1.1935 - val_loss: 0.1612 - val_perplexity: 1.1750\n",
            "Epoch 36/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1761 - perplexity: 1.1926\n",
            "Epoch 36: val_perplexity improved from 1.17499 to 1.17448, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-36-1.1745.hdf5\n",
            "4375/4375 [==============================] - 2013s 460ms/step - loss: 0.1761 - perplexity: 1.1926 - val_loss: 0.1608 - val_perplexity: 1.1745\n",
            "Epoch 37/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1760 - perplexity: 1.1925\n",
            "Epoch 37: val_perplexity did not improve from 1.17448\n",
            "4375/4375 [==============================] - 1991s 455ms/step - loss: 0.1760 - perplexity: 1.1925 - val_loss: 0.1610 - val_perplexity: 1.1747\n",
            "Epoch 38/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1758 - perplexity: 1.1922\n",
            "Epoch 38: val_perplexity improved from 1.17448 to 1.17419, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-38-1.1742.hdf5\n",
            "4375/4375 [==============================] - 2006s 459ms/step - loss: 0.1758 - perplexity: 1.1922 - val_loss: 0.1605 - val_perplexity: 1.1742\n",
            "Epoch 39/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1832 - perplexity: 1.2013\n",
            "Epoch 39: val_perplexity did not improve from 1.17419\n",
            "4375/4375 [==============================] - 1997s 457ms/step - loss: 0.1832 - perplexity: 1.2013 - val_loss: 0.1615 - val_perplexity: 1.1754\n",
            "Epoch 40/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1752 - perplexity: 1.1915\n",
            "Epoch 40: val_perplexity did not improve from 1.17419\n",
            "4375/4375 [==============================] - 1994s 456ms/step - loss: 0.1752 - perplexity: 1.1915 - val_loss: 0.1607 - val_perplexity: 1.1745\n",
            "Epoch 41/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1754 - perplexity: 1.1919\n",
            "Epoch 41: val_perplexity improved from 1.17419 to 1.17406, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-41-1.1741.hdf5\n",
            "4375/4375 [==============================] - 2008s 459ms/step - loss: 0.1754 - perplexity: 1.1919 - val_loss: 0.1604 - val_perplexity: 1.1741\n",
            "Epoch 42/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1752 - perplexity: 1.1916\n",
            "Epoch 42: val_perplexity improved from 1.17406 to 1.17368, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-42-1.1737.hdf5\n",
            "4375/4375 [==============================] - 1999s 457ms/step - loss: 0.1752 - perplexity: 1.1916 - val_loss: 0.1601 - val_perplexity: 1.1737\n",
            "Epoch 43/100\n",
            "4375/4375 [==============================] - ETA: 0s - loss: 0.1750 - perplexity: 1.1913\n",
            "Epoch 43: val_perplexity improved from 1.17368 to 1.17359, saving model to /content/drive/MyDrive/Best_Model_L1_revised/weights-43-1.1736.hdf5\n",
            "4375/4375 [==============================] - 2000s 457ms/step - loss: 0.1750 - perplexity: 1.1913 - val_loss: 0.1600 - val_perplexity: 1.1736\n",
            "Epoch 44/100\n",
            " 264/4375 [>.............................] - ETA: 26:50 - loss: 0.1730 - perplexity: 1.1889"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the best found model"
      ],
      "metadata": {
        "id": "1lxpHIdNQXQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Best_Model_L1_revised/weights-42-1.1737.hdf5',custom_objects = {'perplexity':perplexity})\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8FsH0-jdKOJ",
        "outputId": "cfc3456f-2132-4b86-c26f-4766f5a6dabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 149)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 149, 100)     5000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 149, 512),   549888      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    5000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['bidirectional[0][1]',          \n",
            "                                                                  'bidirectional[0][2]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, None, 512),  943104      ['embedding_1[0][0]',            \n",
            "                                 (None, 512)]                     'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 512)    0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    65664       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 128)    0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 50000)  6450000     ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,008,656\n",
            "Trainable params: 8,008,656\n",
            "Non-trainable params: 10,000,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Function"
      ],
      "metadata": {
        "id": "EXK60qdDQcCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_trail(input_sentence):\n",
        "  en_sen = bpemb_en.encode_ids_with_bos_eos(input_sentence)\n",
        "  de_sen = [[1]]\n",
        "  encoder_input_train = keras.preprocessing.sequence.pad_sequences([en_sen], maxlen=149, padding=\"post\")\n",
        "  decoder_input_train = np.array(de_sen)\n",
        "  embedding_en = new_model.layers[1](encoder_input_train)\n",
        "  encoder_output,state_f,state_b=new_model.layers[3](embedding_en)\n",
        "  concatenated = new_model.layers[5]([state_f,state_b])\n",
        "  start_flag = 1\n",
        "  result = []\n",
        "  for i in range(0,152):\n",
        "    embedding_de = new_model.layers[4](decoder_input_train)\n",
        "    output,state = new_model.layers[6](embedding_de, initial_state = concatenated)\n",
        "    dense = new_model.layers[8](output)\n",
        "    dense1 = new_model.layers[10](dense)\n",
        "    index = np.argmax(dense1[0][0])\n",
        "    de_sen = [[int(index)]]\n",
        "    decoder_input_train = np.array(de_sen)\n",
        "    result.append(int(index))\n",
        "    concatenated = state\n",
        "    if(index == 0):\n",
        "      break\n",
        "  return result"
      ],
      "metadata": {
        "id": "0VJyTZv6XtvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the output given by the decoder"
      ],
      "metadata": {
        "id": "1nY6RNOBQfcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    'here is a',\n",
        "    'have have a',\n",
        "    'pleaseeeee review',\n",
        "    'please call me',\n",
        "    'thanks for the',\n",
        "    'Let me know if yu',\n",
        "    'this sounds',\n",
        "    'is this call going to',\n",
        "    'can you get',\n",
        "    'is it okay',\n",
        "    'it should',\n",
        "    'call if there\\'s',\n",
        "    'gave her a',\n",
        "    'i will let',\n",
        "    'i will lettt',\n",
        "    'may i get a copy of all the',\n",
        "    'how is our trade',\n",
        "    'looks like a',\n",
        "    'i am fine with the changes',\n",
        "    'please be sure this'\n",
        "]\n",
        "\n",
        "output = list(map(lambda text: (text, bpemb_en.decode_ids(predict_trail(text))), texts))\n",
        "output_df = pd.DataFrame(output, columns=[\"input\", \"output\"])\n",
        "output_df.head(len(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "c7syBRn3oTL2",
        "outputId": "cbd16b21-d6f4-400e-b500-70e6356ff856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          input  \\\n",
              "0                     here is a   \n",
              "1                   have have a   \n",
              "2             pleaseeeee review   \n",
              "3                please call me   \n",
              "4                thanks for the   \n",
              "5             Let me know if yu   \n",
              "6                   this sounds   \n",
              "7         is this call going to   \n",
              "8                   can you get   \n",
              "9                    is it okay   \n",
              "10                    it should   \n",
              "11              call if there's   \n",
              "12                   gave her a   \n",
              "13                   i will let   \n",
              "14                 i will lettt   \n",
              "15  may i get a copy of all the   \n",
              "16             how is our trade   \n",
              "17                 looks like a   \n",
              "18   i am fine with the changes   \n",
              "19          please be sure this   \n",
              "\n",
              "                                               output  \n",
              "0       lot of the org for the org of the org game ⁇   \n",
              "1                                    great weekend ⁇   \n",
              "2                                                  ⁇   \n",
              "3                        if you have any questions ⁇   \n",
              "4                                             help ⁇   \n",
              "5           know you need to get a nomination form ⁇   \n",
              "6                                             good ⁇   \n",
              "7   the org and name and name and i shall be glad ...  \n",
              "8   a copy of the org spreadsheet, i am missing th...  \n",
              "9                                                  ⁇   \n",
              "10                                 be a great time ⁇   \n",
              "11                                             you ⁇   \n",
              "12                                      org of org ⁇   \n",
              "13                                        you know ⁇   \n",
              "14                             to be in the office ⁇   \n",
              "15                                             org ⁇   \n",
              "16                                                 ⁇   \n",
              "17                                       good time ⁇   \n",
              "18                              of the org program ⁇   \n",
              "19                                  is a good time ⁇   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e99b9f4-7d4f-4aea-b972-054f9f6fd135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>here is a</td>\n",
              "      <td>lot of the org for the org of the org game ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>have have a</td>\n",
              "      <td>great weekend ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pleaseeeee review</td>\n",
              "      <td>⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please call me</td>\n",
              "      <td>if you have any questions ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks for the</td>\n",
              "      <td>help ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Let me know if yu</td>\n",
              "      <td>know you need to get a nomination form ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>this sounds</td>\n",
              "      <td>good ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is this call going to</td>\n",
              "      <td>the org and name and name and i shall be glad ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>can you get</td>\n",
              "      <td>a copy of the org spreadsheet, i am missing th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>is it okay</td>\n",
              "      <td>⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>it should</td>\n",
              "      <td>be a great time ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>call if there's</td>\n",
              "      <td>you ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>gave her a</td>\n",
              "      <td>org of org ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i will let</td>\n",
              "      <td>you know ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>i will lettt</td>\n",
              "      <td>to be in the office ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>may i get a copy of all the</td>\n",
              "      <td>org ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>how is our trade</td>\n",
              "      <td>⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>looks like a</td>\n",
              "      <td>good time ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i am fine with the changes</td>\n",
              "      <td>of the org program ⁇</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>please be sure this</td>\n",
              "      <td>is a good time ⁇</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e99b9f4-7d4f-4aea-b972-054f9f6fd135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e99b9f4-7d4f-4aea-b972-054f9f6fd135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e99b9f4-7d4f-4aea-b972-054f9f6fd135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The final perplexity score on test data points "
      ],
      "metadata": {
        "id": "nsvTzxU9Qlgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = new_model.evaluate([encoder_input_test, decoder_input_test], decoder_target_test)\n",
        "print(\"%s: %.2f\" % (new_model.metrics_names[1], scores[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq_gfaKicsqY",
        "outputId": "ac894ceb-5f51-4c01-d363-fe73b0cd5608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9375/9375 [==============================] - 684s 73ms/step - loss: 0.1517 - perplexity: 1.1641\n",
            "perplexity: 1.16\n"
          ]
        }
      ]
    }
  ]
}